{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab4efa36",
   "metadata": {},
   "source": [
    "# Data Scientist Interview Questions\n",
    "## Deep Learning and Neural Network\n",
    "This Jupyter notebook is a valuable resource for technical interviews on deep learning and neural networks. It consolidates essential questions, offering a comprehensive study tool. Whether reinforcing foundational knowledge or preparing for an interview, it covers key principles and project-related inquiries for success."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc69763e",
   "metadata": {},
   "source": [
    "## List of Questions\n",
    "## Part 1: Deep Learning and Neural Networks\n",
    "### Q0 -What is Deep Learning?\n",
    "\n",
    "- It is a subset of machine learning that involves training artificial neural networks with multiple layers (deep neural networks). \n",
    "- It is used to model complex patterns and representations.\n",
    "- DL models are trained using large amounts of data.\n",
    "- The term \"deep\" refers to the depth of the neural network, which consists of multiple hidden layers through which data is processed.\n",
    "- It eliminates the need for manual feature engineering by automatically learning hierarchical representations from raw data during the training process.\n",
    "\n",
    "    \n",
    "### Q1- What are some real-life applications of deep learning algorithms?\n",
    "- DL is used in various real-life scenarios across different fields.\n",
    "- Here are some common applications for DL:\n",
    "    - **Computer Vision:** object detection, image classification, facial recognition, and autonomous driving\n",
    "    - **Natural Language Processing (NLP):** translation, chatbots, sentiment analysis etc.\n",
    "    - **Healthcare:** medical image analysis, disease diagnosis, personalized treatment etc.\n",
    "    - **Finance:** fraud detection, credit scoring, customer service automation etc. \n",
    "    - **Recommendation Systems:** for e-commerce, social media and advertising etc.\n",
    "    - **Robotics**\n",
    "    - **Autonomous Vehicles**\n",
    "    - **Manufacturing:** such as predictive maintenance, process optimisation, quality control\n",
    "\n",
    "### Q2- What are the common types of deep learning ?\n",
    "- Artificial Neural Network (ANN)\n",
    "- Convolutional Neural Networks (CNNs):\n",
    "- Recurrent Neural Networks (RNNs)\n",
    "- Autoencoders\n",
    "- Transformers\n",
    "- Generative Adversarial Networks (GANs)\n",
    "- Graph Neural Networks (GNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12417773",
   "metadata": {},
   "source": [
    "###  Q3- What is neural network?\n",
    "- A neural network is a computational model which, has the same operational structure like the way biological neural networks in the human brain works.\n",
    "- Neural networks are designed to recognize patterns, perform tasks, and make decisions by learning from data.\n",
    "- It is an important component of deep learning and artificial intelligence.\n",
    "- Here are the characteristics and components of neural networks:\n",
    "    - Neurons\n",
    "    - Layers\n",
    "    - Connections (Weights)\n",
    "    - Activation Function\n",
    "    - Feedforward and Backpropagation\n",
    "    - Learning\n",
    "    \n",
    "<div>\n",
    "<img src=\"images/neuralnet2.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "*source : https://medium.com/@parekhdhruvish1331/getting-into-deep-learning-c6b270e43055\n",
    "\n",
    "### Q4- What does Neurons mean in NN?\n",
    "- They are nodes or computational units that are considered as basic building blocks of a neural network.\n",
    "- They are inspired by the neurons in the human brain.\n",
    "- They are used to process and transmit information. \n",
    "- They works as follow:\n",
    "   - They receive input \n",
    "   - Then, apply to them a mathematical operation\n",
    "   - Finally, they produce an output.\n",
    "- Each layer of NN has multiple number of neurons which are interconnected together.\n",
    "- The strength of these connections defined as weights that are used to determine the contribution of each neuron's output to the next layer. \n",
    "\n",
    "### Q5- What are the main Layers of NN?\n",
    "- An ANN has three main layers:\n",
    "    - **Input Layer:** receives the initial input data and passes it on to the next layer.\n",
    "    - **Hidden Layers:** intermediate layers that process the input and generate output.\n",
    "    - **Output Layer:** produces the final output or prediction based on the computations performed in the hidden layers..   \n",
    "- Each subset of neurons belongs to a layer. \n",
    "- Depending on the architecture of our NN, the number and configuration of network hidden layers can vary.\n",
    "- Knowing that, we have different types of NN architectures, such as feedforward, recurrent, and convolutional etc. where each architecture has its own specific layer configurations\n",
    "\n",
    "<div>\n",
    "<img src=\"images/neural_network.png\" width=\"300\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f980c",
   "metadata": {},
   "source": [
    "### Q6- What does Connections (Weights) mean in NN?\n",
    "- They are the parameters used to determine the relationship strength between neurons in consecutive layers. \n",
    "- Each connection is associated with a weight which is used to determine the contribution of the neuron's output to the next layer.\n",
    "- During training, NNs learn from data through the adjustment of weights based on the error between the predicted output and the actual output. \n",
    "- This adjustment is accomplished using optimization algorithms such as gradient descent.\n",
    "- The learning process enables the network to recognize patterns, generalize from examples, and make predictions on new, unseen data.\n",
    "\n",
    "### Q7- What are the various activation functions used in NN?\n",
    "- Each neuron has an activation function that determines its output based on the weighted sum of its inputs.\n",
    "- They help in transforming the output of the neural network into a suitable format for the specific problem domain.\n",
    "\n",
    "- Common activation functions are:\n",
    "    - Sigmoid\n",
    "    - Hyperbolic tangent (tanh)\n",
    "    - Rectified linear unit (ReLU)\n",
    "    - Leaky ReLU\n",
    "    - Softmax\n",
    "    - Swish\n",
    "    \n",
    "- The choice of the activation function depends on the tak: \n",
    "   - Binary Classification (Single Output Neuron): Sigmoid or Logistic function.\n",
    "   - Multiclass Classification (Multiple Output Neurons): Softmax function.\n",
    "   - Regression (Single Output Neuron): ReLU (Rectified Linear Unit) or no activation function (identity function).\n",
    "\n",
    "    \n",
    "<div>\n",
    "<img src=\"images/neural1.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "### Q8- Explain the Sigmoid function ?\n",
    "- Formula : $σ(x) = {1 \\over 1 + e^{-x}}$\n",
    "- It compresses the input values, making sure they're all between 0 and 1.\n",
    "- Used for binary Classification. \n",
    "- However, it suffers from the vanishing gradient problem.\n",
    "- Illustration :\n",
    "     \n",
    "<img src=\"images/sigmoid-function.png\" width=\"350\"/>\n",
    "   \n",
    "** Source: https://www.codecademy.com/resources/docs/ai/neural-networks/sigmoid-activation-function   \n",
    "\n",
    "### Q9- Explain the Softmax function ?\n",
    "- Formula : $softmax(x_i) = {e^{x_i} \\over \\sum_{j=1}^{n}e^{x_j}}$\n",
    "- It converts the output of a NN into a probability distribution over multiple classes. \n",
    "- Suitable for multi-class classification problems.\n",
    "- Illustration :\n",
    "\n",
    "<img src=\"images/Softmax1.png\" width=\"350\"/>\n",
    "\n",
    "** Source : https://botpenguin.com/glossary/softmax-function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e767072",
   "metadata": {},
   "source": [
    "### Q9- Explain ReLU (Rectified Linear Unit) function      \n",
    "- Formula : ReLU(x)=max(0,x), ReLU  returns x if x is positive, and 0 otherwise.\n",
    "- It sets all negative values to zero and leaves positive values unchanged.\n",
    "- It is widely used due to its simplicity and effectiveness in training deep neural networks.\n",
    "- Illustration :\n",
    "     \n",
    "<img src=\"images/Relu.png\" width=\"350\"/>\n",
    "\n",
    "** Source : https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/\n",
    "\n",
    "### Q10- Explain Hyperbolic tangent (tanh) function\n",
    "- Formula: $tanh(x) = {e^x - e^{-x} \\over e^x + e^{-x}}$\n",
    "- Similar to the sigmoid function, but it squashes the input values between -1 and 1.\n",
    "- It is often used in recurrent neural network\n",
    "- Illustration :\n",
    "\n",
    "<img src=\"images/tanh.png\" width=\"350\"/>\n",
    "\n",
    "** Source: https://en.m.wikipedia.org/wiki/File:Hyperbolic_Tangent.svg\n",
    "\n",
    "### Q11- Explain Leaky ReLU function\n",
    "\n",
    "- Formula: $ReLU_{Leaky}(x) = { x\\  if\\ x > 0,\\ alpha \\times x\\ if\\ x <= 0 }$, where is a small positive constant, typically in the range of 0.01 to 0.3, which determines the slope of the function for negative input values.\n",
    "- It is similar to ReLU.\n",
    "- However, it allows a small, positive gradient for negative inputs, which helps mitigate the \"dying ReLU\" problem.\n",
    "- Illustration :\n",
    "<img src=\"images/LeakyReLU.png\" width=\"350\"/>\n",
    "\n",
    "** Source: https://www.researchgate.net/figure/ReLU-activation-function-vs-LeakyReLU-activation-function_fig2_358306930\n",
    "\n",
    "### Q12- Explain Swish function\n",
    "- Formula: $Swish(x) ={x . sigmoid(x)} = {x \\over 1 + e^{-x}}$\n",
    "- Proposed as an alternative to ReLU. \n",
    "- Swish is a smooth, non-monotonic activation function. \n",
    "- It is preferred to be used in various neural networks because it often works really well.\n",
    "- Illustration :\n",
    "<img src=\"images/Swish.png\" width=\"350\"/>\n",
    "\n",
    "** Source: https://www.researchgate.net/figure/Self-Gated-Swish-Activation-Function-3_fig1_359571434"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3cb0dc",
   "metadata": {},
   "source": [
    "### Q12- What Is a Multi-layer Perceptron(MLP)?\n",
    "- It is a type of ANN composed of multiple layers of neurons or nodes. \n",
    "- It has the next architecture:\n",
    "    - One input layer\n",
    "    - One or more hidden layers\n",
    "    - One output layer\n",
    "- As defined previously, weight is associated to each connection and each neuron is connected to all neurons in the consecutive layer.\n",
    "- It has significant role in ML as it is able to learn complex patterns and nonlinear relationships in the data. \n",
    "- Actually, neurons use nonlinear activation functions which make the network able to learn complex patterns in data. \n",
    "- MLP is trained using backpropagation technique, where weights are adjusted to minimize the difference between its predictions and the true target values.\n",
    "- MLP is used for multiple tasks: \n",
    "  - Classification\n",
    "  - Regression \n",
    "  - Pattern recognition\n",
    "  \n",
    "### Q13- What is Shallow neural network?\n",
    "\n",
    "- It is a single-layer neural network that has only one hidden layer between the input and output layers.\n",
    "- It is simple and computationally efficient. \n",
    "- Each neuron in the hidden layer receives inputs from the input layer.\n",
    "- Then, performs a weighted sum of these inputs, applies an activation function\n",
    "- Finally, passes the result to the output layer.\n",
    "- Shallow neural network can be used for simple linear classification or regression tasks.\n",
    "  \n",
    "### Q14- What is Deep neural network?\n",
    "\n",
    "- It is a type of ANN that has multiple hidden layers\n",
    "- It consist of an input layer, one or more hidden layers, and an output layer.\n",
    "- Each layer has multiple neurons which perform computations on the input data using weighted connections and activation functions.\n",
    "- During the training phase, DNN uses backpropagation and gradient descent algorithm to adjust the weights and connections biases based on minimizing the difference between predicted and actual outputs.\n",
    "- DNN is able to learn complicated patterns and representations in data.\n",
    "- They are more suitable for complex tasks such as : natural language processing, image recognition and speech recognition.\n",
    "\n",
    "\n",
    "### Q15- Deep neural networks versus Shallow neural networks :\n",
    "\n",
    "- **Shallow neural networks:**\n",
    "    - Simple architecture : only one hidden layer.\n",
    "    - They are more used with simple tasks, where the data has simple patterns or relationships.\n",
    "    - They are suitable for cases when the dataset is small.  \n",
    "    - They have a limited capacity to learn complex patterns in data.\n",
    "    - They are simple, easier to train and computationally efficient. \n",
    "    \n",
    "- **Deep neural networks:** \n",
    "    - They have complex architecture with multiple hidden layers.\n",
    "    - They can capture and learn more complex patterns and non-linear relationships in data.\n",
    "    - They are suitable for more challenging and complicated tasks with large amount of data.\n",
    "    - They require more computational resources and large amount of labeled data to achieve optimal performance during training phase. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc616189",
   "metadata": {},
   "source": [
    "### Q16- What types of data processing are typically performed in neural networks?\n",
    "Typically, data processing in neural networks involves several steps:\n",
    "- **Data Cleaning:** handling missing values, ensuring data coherence and removing outliers\n",
    "- **Data Normalization:** scaling numerical features to a standard range.\n",
    "- **Feature Engineering:** creating new features or transforming existing ones\n",
    "- **Encoding Categorical features:** converting categorical variables into numerical form suitable for neural networks.\n",
    "- **Data Augmentation:** generating additional training samples \n",
    "- **Dimensionality Reduction:** reducing the number of features\n",
    "- **Train-Test Split:** splitting the dataset into training and testing subsets. \n",
    "- **Data Balancing:** addressing class imbalances by oversampling, undersampling, or using techniques like SMOTE.\n",
    "\n",
    "### Q17- Why do we need Data Normalization in neural networks?\n",
    "- It is used to achieve stable and fast training of the model\n",
    "- It aims to bring all the features to a certain scale or range of values, usually between 0 and 1. \n",
    "- Without normalization, there's a higher risk of the gradient descent failing to converge to the global or local minima and instead oscillating back and forth.\n",
    "- Normalized data reduces the likelihood of numerical instability that can occur when working with features with vastly different scales.\n",
    "- It is used to prevent overfitting and improve the generalization ability of the model.\n",
    "- Normalizing features ensures that they contribute equally to the model's learning process. \n",
    "\n",
    "### Q18- Why do we need Data Augmentation in neural networks?\n",
    "Here are some points why Data Augmentation is important in neural network: \n",
    "- Increase the model robustness and improve performance via exposing it to a larger number of various data samples.\n",
    "- Enhance the model generalization ability and improve performance. \n",
    "- Mitigating and reducing overfitting.\n",
    "- It increases the effective size of the dataset to overcome the lack of data issue. Especially, when the provided dataset is so small. \n",
    "- It helps in reducing the dependency on Large Datasets -> the need for collecting and annotating large datasets is reduced.\n",
    "- Training process is more cost effective \n",
    "\n",
    "### Q19- What does Image augmentation mean?\n",
    "\n",
    "- An efficacious Technique when we do not have enough amount of data to train a DL model.\n",
    "- It aims to increase the diversity of images in a dataset via applying various transformations to images : \n",
    "   - Rotation\n",
    "   - Scaling and resizing\n",
    "   - Cropping and flipping\n",
    "   - Changing color and brightness\n",
    "- It increases the diversity of the dataset without collecting new data.\n",
    "- It helps improve the robustness and generalization ability of models by exposing it to a wider range of variations.\n",
    "- It is widely used in computer vision tasks such as object detection and classification.\n",
    "- It is very useful when dealing with limited or imbalanced datasets.\n",
    "- It helps prevent overfitting and improves model performance on unseen data.\n",
    "- DL frameworks such as TensorFlow and PyTorch provide built-in support for image augmentation.\n",
    "- Augmentation parameters must be chosen carefully \n",
    "\n",
    "\n",
    "### Q20- How to address the problem of class imbalance ?\n",
    "- It is important to address the class imbalance issue in neural networks to ensure that the model learns effectively from all exisitng classes. \n",
    "- Here are some common techniques to mitigate class imbalance:\n",
    "    - **Data Augmentation:** generate artificial samples for minority classes.\n",
    "    - **Resampling Techniques:**\n",
    "        - Oversampling: increase the number of samples in the minority class by replicating existing samples or generating synthetic data.\n",
    "        - Undersampling: Decrease the number of samples in the majority class to match the size of the minority class.\n",
    "    - **Ensemble Methods:** various models are trained on different subsets of data or different algorithms are used, then merge their predictions to handle class imbalance.\n",
    "    - **Cross-Validation techniques:** use validation techniques such as k-fold cross-validation.\n",
    "    - **Weighted loss functions** which give more importance to minority class samples (Assign higher weights to the loss) during training, helping the model better learn from these instances and improve performance on imbalanced datasets.\n",
    "    - **Use Specific algorithms:** which are designed to handle class imbalance, such as SMOTE (Synthetic Minority Over-sampling Technique) or ADASYN (Adaptive Synthetic Sampling).\n",
    "    - **Choose the right Evaluation Metrics:** in case of class imbalance accuracy alone is not a robust or an accurate metric. Instead, we can use precision, recall, F1-score or ROC-AUC. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a0d99e",
   "metadata": {},
   "source": [
    "### Q20- What Are Hyperparameters and parameters of neural network?\n",
    "- Neural network has several important hyperparameters and parameters. \n",
    "- Hyperparameters guide the learning process, while parameters are learned from data during training.\n",
    "- **Hyperparameters:**\n",
    "   - Set before the training process.\n",
    "   - Control the model's architecture and learning process.\n",
    "   - Tuning hyperparameters affects model performance.\n",
    "   - Examples: learning rate, batch size, and number of layers.\n",
    "\n",
    "- Parameters:\n",
    "   - Learned during the training process.\n",
    "   - Adjusted iteratively to minimize the loss/cost function.\n",
    "   - Define the model's ability to capture patterns in the data.\n",
    "   - Examples: weights and biases in the network's connections.\n",
    "\n",
    "### Q21- What is the Learning rate in neural network and how  to choose its optimal value? \n",
    "- It is an hyperparameter of the model. \n",
    "- It aims to control the step size taken during updating the weights of the network. \n",
    "- It determines how much the model's parameters (weights) are adjusted with respect to the loss / cost function. \n",
    "- During the optimization process, we aim to minimize the gradient descent loss function\n",
    "- The loss function corresponds to the difference between predicted and actual outputs.\n",
    "- Choosing the optimal learning rate is crucial for achieving better performance :\n",
    "  - High : faster convergence and might lead to overshooting the optimal solution.\n",
    "  - Low: slower convergence but more stable training. \n",
    "- To choose the optimal learning rate, we use techniques like :\n",
    "   - Grid search\n",
    "   - Random search\n",
    "   - Leverage adaptive learning rate algorithms : AdaGrad, RMSprop, or Adam.\n",
    "\n",
    "### Q22- What is batch size in neural network ? \n",
    "- It corresponds to the number of training samples used in one iteration.\n",
    "- It determines how many samples are propagated through the network before updating the model parameters during training.\n",
    "- It is considered as an hyperparameter in neural network training.\n",
    "- Adjusting the batch size can affect the convergence speed and generalization of the model\n",
    "- It is an important aspect to tune during the training process.\n",
    "\n",
    "### Q23- How to choose the best batch size ?\n",
    "- Several factors must be considered while choosing the best batch size. \n",
    "- Factors can be : dataset size, model complexity, available computational resources, and training objectives\n",
    "- However, it is important to try with different batch sizes to identify the best one for your specific task and constraints.\n",
    "- Here are some ideas how to choose the right value :\n",
    "   - Consider hardware limitations and dataset size: large datasets requires large memory and expensive computational resources.\n",
    "   - Try various batch sizes : a range between 10 and 250 and choose the size that optimizes training speed and accuracy.\n",
    "   - Balance between speed and accuracy: \n",
    "       - Smaller batch sizes may lead to slower convergence but: can provide more noise in gradient estimation + potentially leading to better generalization. \n",
    "       - Larger batch sizes may speed up training but could result in poorer generalization.\n",
    "   - Consider total dataset size :\n",
    "       - For large datasets: smaller batches can still offer sufficient randomness\n",
    "       - For smaller datasets: bigger batches might be better.\n",
    "   - Smaller batch sizes can help in mitigating overfitting during the optimization process\n",
    "\n",
    "### Q24- What Is the difference between Epoch, Batch, and Iteration in Deep Learning?\n",
    "\n",
    "In deep learning:\n",
    "\n",
    "- Epoch: One pass through the entire dataset.--> numder of epochs defines the number of times the algorithm sees the entire dataset.\n",
    "- Batch: Subset of the dataset used in one iteration.\n",
    "- Iteration: One update of the model's parameters using one batch of data.\n",
    "- An epoch consists of multiple iterations, and each iteration processes one batch of data.\n",
    " \n",
    "### Q25- What is the significance of using the Fourier transform in Deep Learning tasks?\n",
    "- It plays a crucial role in deep learning as it used for several tasks:\n",
    "    -  **Feature Extraction:** extract frequency-domain features from signals or images, aiding in the representation of data for deep learning models.\n",
    "    - **Data Preprocessing:** such as denoising, smoothing signals and remove irrelevant components, before feeding them into neural networks. \n",
    "    - **Data Augmentation:** applying transformations (Fourier transform and its variants, such as the Short-Time Fourier Transform (STFT) like rotation or scaling in the frequency domain.\n",
    "    - **Efficient Convolution:** it can be used to implement convolution operations in convolutional neural networks (CNNs) and reducing computational complexity.\n",
    "    - **Time-Series Analysis:** used to analyze time-series data or audio signals, and identify patterns or anomalies effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867747cf",
   "metadata": {},
   "source": [
    "### Tensorflow, Keras and Pytorch\n",
    "### Q26- What is Tensorflow and what it is used for?\n",
    "- It is an Open-source machine learning framework by Google.\n",
    "- It aims to Build, train, and deploy machine learning models.\n",
    "- Key features: it supports neural networks, including deep learning models.\n",
    "- Itallows users to build complex neural network architectures using high-level APIs like Keras or through its own lower-level API.\n",
    "- It perform efficient training on large datasets, including distributed training across multiple GPUs or TPUs (Tensor Processing Units).\n",
    "- Used to develop and deploy models for making predictions on new data.\n",
    "- It offers an advanced visualization tools that are used for monitoring and analyzing model performance.\n",
    "- It supports various deployment options, including exporting models to different formats for deployment on different platforms, such as mobile devices or the web.\n",
    "- It is widely used in research and industry for tasks like image recognition and NLP.\n",
    "\n",
    "### Q27- What are the programming elements in Tensorflow?\n",
    "\n",
    "In TensorFlow, the main programming elements include:\n",
    "\n",
    "- **Tensors:** fundamental data structures representing multi-dimensional arrays.\n",
    "- **Variables:** mutable tensors that can hold state that can be updated during computation.\n",
    "- **Constants:** parameters whose value does not change.\n",
    "- **Placeholders:** allow us to feed data to a tensorflow model from outside a model\n",
    "- **Layers:** high-level abstractions for building neural network layers.\n",
    "- **Sessions:** execution environments where operations are evaluated and tensors are computed.\n",
    "- **Operations:** mathematical operations that can be performed on tensors.\n",
    "- **Graphs:** computational graphs that define the flow of data and operations.\n",
    "- **Estimators:** high-level API for training and evaluating TensorFlow models.\n",
    "- **Optimizers:** algorithms for optimizing the parameters of a model during training.\n",
    "- **Loss Functions:** functions that compute the error or loss between predicted and actual values.\n",
    "- **Metrics:** functions for evaluating the performance of a model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa391a",
   "metadata": {},
   "source": [
    "### Q28- What does Tensor mean in Tensorflow?\n",
    "- Tensor corresponds to fundamental data structures representing a multi-dimensional array that can be vectors, matrices and even complex data structures.\n",
    "- The term \"tensor\" is a mathematical concept that represents data with multiple dimensions.\n",
    "- In Tensorflow setup, a tensor can be considered as a container that can hold data in multiple dimensions.\n",
    "- The data could be input data, model parameters, and outputs that is passed between operations in a computational graph.\n",
    "- Tensorflow, perform mathematical operations on this data efficiently, even if it is of large-scale data. \n",
    "\n",
    "### Q29- What placeholders mean in Tensorflow ? \n",
    "- First, they are used to create a computational graph. \n",
    "- At the beginning, they are considered as empty variables, that will be fill with data during execution (running the graph).\n",
    "- Then, they allow us to feed data to a tensorflow model (a computational graph) from outside a model, when running the graph. \n",
    "- They are typically used to define the input and target data for training a machine learning model.\n",
    "- To define a placeholder, we use the `tf.placeholder()` command. \n",
    "- This separation of graph definition and data feeding enables flexibility and efficiency in TensorFlow's execution.\n",
    "### Q30-  Explain a Computational Graph.\n",
    "- TensorFlow operates via constructing a computational graph.\n",
    "- In the computational graph we have: \n",
    "    - Interconnected Nodes that correspond to mathematical operations such as  addition, multiplication, or convolution\n",
    "    - Edges represent tensors, which are multi-dimensional arrays carrying data between nodes (data flow).\n",
    "- By using operations within the graph, TensorFlow allows for dynamic computation and optimization during execution.\n",
    "- This structure forms a \"DataFlow Graph,\" enabling efficient computation and optimization of machine learning models.\n",
    "- This graph-based approach facilitates distributed computing and parallel execution, enhancing scalability and performance.\n",
    "### Q31- What do Variables and Constants mean in TensorFlow? \n",
    "- First of all, Variables and Constants are two important elements in building and training machine learning models using TensorFlow.\n",
    "- **Variables:**\n",
    "    - Mutable tensors that hold values that can be updated during computation,\n",
    "    - They are typically used to represent trainable parameters, such as weights, biases, in machine learning models.\n",
    "    - To define a variable, we use the `tf.Variable()` command and initialize them before running the graph in a session\n",
    "    - Example : W = tf.Variable([.5].dtype=tf.float32)\n",
    "- **Constants:**\n",
    "    - Immutable tensors whose values remain fixed and constant during the execution of a TensorFlow graph\n",
    "    - They are typically used to represent fixed values or hyperparameters in a model.\n",
    "    - To define a constant we use  `tf.constant()` command.\n",
    "    - Example: `a = tf.constant(6.0,tf.float32)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe1c2fb",
   "metadata": {},
   "source": [
    "### Q31- Explain Session in TensorFlow \n",
    "- It is an execution environment for running operations or evaluating tensors.\n",
    "- It encapsulates the control and state of the TensorFlow runtime, allowing to perform computations on the defined computational graph.\n",
    "- It manages the resources (memory allocation and device management) required for running the computations efficiently.\n",
    "- It maintains the state of variables and other resources throughout the execution\n",
    "- Here are how you should use Session:\n",
    "    - First create a Session object in your TensorFlow program using `with tf.Session() as sess:` command\n",
    "    - Then, run operations and evaluate tensors within the context of the Session using `sess.run(...)`\n",
    "- TensorFlow setup gives you the flexibility in managing the flow of computations via having control over when to start and end the execution of operations within the Session.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23399271",
   "metadata": {},
   "source": [
    "### Q32- What is Keras and what it is used for ?\n",
    "- It is a Python-based open-source framework, that simplifies the process of developing deep learning models.\n",
    "- It offers a user-friendly API and a high-level interface for building, training, and deploying neural networks enabling rapid development and experimentation.\n",
    "- Models in Keras are built using layers, which can be easily stacked and configured to create complex architectures.\n",
    "- It supports both **convolutional and recurrent neural networks**, as well as combinations of the two.\n",
    "- Also, it provides support for custom layers, loss functions, and metrics.\n",
    "- It allows creating custom layers, callbacks, and regularizers tailored to specific requirements or tasks.\n",
    "- Compatible with multiple backends, including TensorFlow, Theano, etc.\n",
    "- Simplifies the process of developing deep learning models for various applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5aecbf",
   "metadata": {},
   "source": [
    "### Q33- What is Pytorch and what it is used for ?\n",
    "\n",
    "- It is an open-source machine learning framework used for building deep learning models.\n",
    "- It supports both:\n",
    "    - Traditional feedforward networks\n",
    "    - Advanced architectures like RNNs and CNNs.\n",
    "- It has an automatic differentiation engine that enables gradient-based optimization methods for training neural networks. \n",
    "- It allows efficient gradients computation and complex optimization algorithms implementation simplification.\n",
    "- It is widely used in research (enable explore new ideas and algorithms quickly) and industry (model serialization, inference optimization, and integration with other frameworks and platforms) for various machine learning tasks.\n",
    "- It integrates smoothly with GPUs, accelerating computation for training large-scale models and handling massive datasets efficiently.\n",
    "- It is used in many fields such as: \n",
    "    - Computer vision\n",
    "    - Natural language processing\n",
    "    - Reinforcement learning\n",
    "\n",
    "**Notes:**\n",
    "- RNNs: Recurrent Neural Networks\n",
    "- CNNs: Convolutional Neural Networks\n",
    "\n",
    "\n",
    "### Q34- Why is Tensorflow the most preferred Library in Deep Learning?\n",
    "- **Flexibility:** it allows building a wide range of neural networks, from simple to complex architectures.\n",
    "- **Community Support:** it has a large community with extensive documentation and resources available.\n",
    "- **Performance:** it is optimized for speed and efficiency, utilizing hardware accelerators like GPUs and TPUs.\n",
    "- **Ease of Use:** high-level APIs like Keras make it easy to build and train neural networks with an intuitive interface.\n",
    "- **Deployment Options:** models can be deployed across various platforms, including mobile devices, desktops, servers, and the cloud.\n",
    "- **Continuous Development:** it is actively maintained, receiving regular updates and improvements to stay current with the latest advancements.\n",
    "\n",
    "### Q35- Tensorflow Versus Pytorch\n",
    "- TensorFlow and PyTorch are two popular deep learning frameworks \n",
    "- The choice between them depends on:\n",
    "   - Specific project requirements\n",
    "   - Familiarity with the framework\n",
    "   - Personal preference\n",
    "   \n",
    "- **Tensorflow :**\n",
    "    - Based on theano library.\n",
    "    - Developed By Google and has a larger user base and extensive documentation.\n",
    "    - Easy to use\n",
    "    - It Offers both:\n",
    "      - high-level APIs like Keras for quick development of neural networks\n",
    "      - lower-level APIs for fine-grained control over model architecture.\n",
    "    - Has Tensorboard for visualizing deep learning models\n",
    "    - Better support for deployment in production environments, has tools for mobile and embedded devices: \n",
    "       - TensorFlow Serving \n",
    "       - TensorFlow Lite \n",
    "    - Very performant, particularly on large-scale distributed training and deployment scenarios. \n",
    "    \n",
    "- **Pytorch :**\n",
    "    - Based on Torch library\n",
    "    - Developed by Facebook/ Meta and has an active research community, particularly in academia.\n",
    "    - Offers dynamic computation graphs, which makes it flexible, and easy to debug. \n",
    "    - It is more Pythonic and intuitive for developers.\n",
    "    - Visualization features are existing\n",
    "    - Historically, deployment in production has been more challenging compared to TensorFlow.\n",
    "    - Competitive performance for its efficient GPU utilization and dynamic graph execution.\n",
    "\n",
    "- **In summary:**\n",
    "   - TensorFlow is often favored for its ease of use, deployment capabilities, and extensive ecosystem\n",
    "   - PyTorch is more preferred by researchers and developers who value flexibility, dynamic computation graphs, and Pythonic design.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390b8578",
   "metadata": {},
   "source": [
    "## Part 2: Model training and Evaluation\n",
    "\n",
    "### Q1- What Is the Cost Function? \n",
    "- It is also called loss function\n",
    "- It measures the performance of the neural network model during training phase. \n",
    "- It calculates the difference between predicted and actual/true values. \n",
    "- During the training phase, the main goal is to minimize the cost function via adjusting the model's parameters to improve its accuracy\n",
    "\n",
    "### Q2- What  do you  understand by Feedforward\n",
    "- To train a neural network, we use two main algorithms:\n",
    "  - Feedforward\n",
    "  - Backpropagation\n",
    "- It aims to find predictions and outputs via passing data through the neural network. \n",
    "- The information is following one direction, from input layer to output layer.\n",
    "- It has no feedback loops or recurrent connections. \n",
    "- Each layer in the network takes the input data and transforms it, making it more abstract as it goes.\n",
    "- The final /output layer provides the predictions that are compared to the true / target values to identify the loss or error.  \n",
    "- It does not have memory, therefore, it is used for tasks where the input-output mapping is fixed and does not depend on previous states or inputs.\n",
    "\n",
    "**Notes:**\n",
    "- \"More abstract\" means that the features become less directly related to the raw input data and instead capture higher-level patterns or concepts\n",
    "\n",
    "Unlike recurrent networks, feedforward networks do not have memory and are typically used for tasks where the input-output mapping is fixed and does not depend on previous states or inputs.\n",
    "\n",
    "### Q3- What  do you  understand by Backpropagation?\n",
    "- It is a key algorithm used to train a neural network. \n",
    "- It aims to adjust the model's weights and biases to minimise the cost function and improve the model's accuracy.\n",
    "- It involves propagating the error backward from the output layer to the input layer.\n",
    "- It calculates the gradient of the loss function with respect to each parameter in the network.\n",
    "- It enables efficient optimization using gradient descent or its variants.\n",
    "- Iteratively, it adjusts the model's parameters based on these gradients to improve performance over time.\n",
    "\n",
    "<div>\n",
    "<img src=\"images/feed_back.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2815bcd3",
   "metadata": {},
   "source": [
    "### Q4- What does Optimizer mean in neural network ? \n",
    "- It is a technique used to adjust the attributes, such as weights and biases, of a neural network during training.\n",
    "- It aims to minimize the error or loss function to improve the network's predictive accuracy.\n",
    "- Some popular optimizers: Gradient Descent, Adam, RMSprop.\n",
    "- Each optimizer has its own approach to adjust network parameters based on gradients of the loss function.\n",
    "\n",
    "### Q5- Explain the Adam optimization algorithm?\n",
    "\n",
    "\n",
    "### Q6- Explain the Gradient Descent algorithm?\n",
    "- It is an optimization algorithm used to minimize the cost function.\n",
    "- It aims to find the set of parameters that minimizes error and improves the model’s performance or accuracy.\n",
    "- It perform this task via adjusting parameters iteratively in the direction of the negative gradient.\n",
    "- It can be used in various ML algorithms such as Linear regression, Logistic regression, neural networks etc.\n",
    "- It works as follow :\n",
    "    - **Initialization:** the algorithm starts with an initial set of parameters and updates them in small steps.\n",
    "    - **Calculate Gradient:** calculates the gradient of the cost function, which represents the direction and magnitude of the steepest ascent.\n",
    "    - **Negative Gradient Descent:** since we aim to minimize the cost function, gradient descent moves in the opposite direction of the gradient, known as the negative gradient direction.\n",
    "    - **Iterative Refinement:** the model's parameters are iteratively refined or updated in the negative gradient direction based on the cost function.\n",
    "    - **Convergence:** gradient descent gradually converges towards the optimal set of parameters that yield the lowest cost.\n",
    "    - **Learning Rate:** at each iteration, a learning rate (a hyperparameter) determines the step size taken. It directly influences the speed and stability of convergence.\n",
    "    \n",
    "### Q- How many hyperparameters do we have in Gradient Descent (GD)?\n",
    "\n",
    "- One hyperparameters: the **Learning Rate**.\n",
    "- **Number of Iterations** can also be considered a hyperparameter in some contexts\n",
    "- However, number of Iterations is more commonly referred to as a tuning parameter or a parameter of the optimization process rather than a hyperparameter.\n",
    "- The learning rate and the number of iterations play crucial roles in the performance of gradient descent.\n",
    "\n",
    "### Q- How to determine the optimal hyperparameters ?\n",
    "- Use a grid search or random search across various values.\n",
    "- Iteratively, adjusting the learning rate and number of iterations values.\n",
    "- Evaluate each hyperparameter combination using cross-validation.\n",
    "- At each iteration, monitor training progress and model performance.\n",
    "- Choose the combination that yields the best performance on unseen data.\n",
    "\n",
    "### Q- What are the different variations of gradient descent ?\n",
    "- Actually, each variant is tailored for specific scenarios:\n",
    "   - Batch Gradient Descent\n",
    "   - Stochastic Gradient Descent (SGD)\n",
    "   - Mini-batch Gradient Descent:\n",
    "- Each variant has its pros and cons, making them suitable for different optimization tasks based on:\n",
    "   - Dataset size\n",
    "   - Computational resources\n",
    "   - Convergence requirements\n",
    "   \n",
    "### Q- What is Stochastic Gradient Descent (SGD) ?\n",
    "\n",
    "- Randomly select a single data point or a small subset (mini-batch) from the training set.\n",
    "- Compute the gradient of the cost function and update the parameters using that data point or that mini-batch.\n",
    "- Update the model parameters in the direction of the negative gradient scaled by the learning rate.\n",
    "- Repeat the process for a fixed number of iterations or until convergence is achieved.\n",
    "- Faster convergence but noisy updates due to frequent parameter updates.\n",
    "\n",
    "### Q- What is Batch Gradient Descent ?\n",
    "\n",
    "- Iterates through the entire dataset to calculate the gradient of the cost function.\n",
    "- This means that the gradient is computed with respect to each data point individually.\n",
    "- It updates the model parameters based on the average gradient of all data points.\n",
    "- Provides accurate but slow convergence, especially for large datasets.\n",
    "- Computationally expensive as it requires storing the entire dataset in memory, making it memory-intensive for big data scenarios.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### What Is the Difference Between Batch Gradient Descent and Stochastic Gradient Descent?\n",
    "### What are the reasons for mini-batch gradient being so useful?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada446f6",
   "metadata": {},
   "source": [
    "### Q- How do we initialize Weights in a neural network?\n",
    "\n",
    "### Q- What is the need to add randomness in the weight initialization process?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2a16b",
   "metadata": {},
   "source": [
    "### Q- How to evaluate models in neural networks?\n",
    "\n",
    "### Q- What does model convergence mean?\n",
    "- A state reached during the training of a model when the loss changes very little between each iteration\n",
    "\n",
    "### Q- How to perform hyperparameters tuning in neural network?\n",
    "### How can you train hyperparameters in a neural network?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760eb6af",
   "metadata": {},
   "source": [
    "### Q- How to mitigate overfitting in neural network?\n",
    "\n",
    "\n",
    "- To mitigate overfitting in neural network, we use :\n",
    "    - Dropout\n",
    "    - Data augmentation\n",
    "    - Early stopping\n",
    "\n",
    "\n",
    "### Q- How to mitigate underfitting in neural network?\n",
    "\n",
    "\n",
    "### Q- What does early stopping mean?\n",
    "- A kind of cross-validation strategy when one part of the training set is used as validation set. \n",
    "- If the evaluated performance metric on validation set (unseen data) get worse, the training of the model is immediatly stopped. \n",
    "- The validation is performed on subset of unseen data from input data after each iteration\n",
    "\n",
    "### Q- What does Dropout mean?\n",
    "### What Is Dropout and Batch Normalization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26c1aee",
   "metadata": {},
   "source": [
    "\n",
    "### What is redularization in dl \n",
    "- method that makes slight modification to the learning algorithm such the model generalizes better this in turn to improve the performance on unseen data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c86fe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "020cc066",
   "metadata": {},
   "source": [
    "### Q- What is Vanishing Gradient?\n",
    "### Q- How to deal with the vanishing gradient ?\n",
    "### Q- What is Exploding Gradient?\n",
    "### Q- How to deal with Exploding Gradient?\n",
    "\n",
    "### Q- What are callbacks in neural networks?\n",
    "### Q- What are regularizers used for in neural networks? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f4861b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Can we use bagging and boosting with "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2f131d",
   "metadata": {},
   "source": [
    "### Q- What is tranfert learning? \n",
    "- Called also fine-tuning\n",
    "- Based on using a pre-trained network with adjusting one or more layers. \n",
    "- Has four steps:\n",
    "    - Pre-train a base network on the source dataset\n",
    "    - Create a target neural network architecture and copy trained parameters\n",
    "    - create and random initialize the output layer ==>output layers with different neurons means different classes.\n",
    "    - Train from scratch and fine tune\n",
    " How to train and or fine-tune with strong regularization:\n",
    "     - Smaller learning rate\n",
    "     - fewer epochs ==> for hyper-parameter\n",
    " - If the model is trained over complex dataset (source) then TL over simple dataset ==> high performance\n",
    " \n",
    "### Q- How to use a pre-trained model?\n",
    "Two options :\n",
    "- Option 1: if source dataset like target dataset==> use a fixed pre-trained model (no training is needed)\n",
    "- Option 2: if source dataset is different than target dataset ==> training from scratch, freezing the other pre-trained feature layers. \n",
    "\n",
    "### Q- What are some common used transfer learning models?\n",
    "Some of the popular transfer learning models are:\n",
    "- VGG-16\n",
    "- BERT\n",
    "- GTP-3\n",
    "- Inception V3\n",
    "- XCeption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500d643f",
   "metadata": {},
   "source": [
    "## Part 3:  Advanced neural network architectures.\n",
    "### Recurrent Neural Network (RNN) \n",
    "### What Is the Difference Between a Feedforward Neural Network and Recurrent Neural Network?\n",
    "### What Are the Applications of a Recurrent Neural Network (RNN)?\n",
    "\n",
    "\n",
    "\n",
    "### Convolutional neural network (CNN)\n",
    "### What is Pooling on CNN, and How Does It Work?\n",
    "### Q31- What is the difference between SAME and VALID padding in Tensorflow?\n",
    "### What is LSTM Network and how it Work?\n",
    "### What are the Different Layers on CNN?\n",
    "### Why is a convolutional neural network preferred over a dense neural network for an image classification task?\n",
    "\n",
    "\n",
    "\n",
    "### 2- What is Convolutional Neural Networks : CNNs? \n",
    "### 3- What is Recurrent Neural Networks : RNNs? \n",
    "\n",
    "### Autoencoders \n",
    "\n",
    "\n",
    "### What Is an Auto-encoder?\n",
    "### What are some of the uses of Autoencoders in Deep Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f37e96b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc90d33",
   "metadata": {},
   "source": [
    "### Generative Adversarial Network\n",
    "\n",
    "\n",
    "### Explain Generative Adversarial Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54fb741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
